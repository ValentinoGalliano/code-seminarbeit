\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}

\lstset{
  basicstyle=\ttfamily\small,
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=5pt,
  backgroundcolor=\color{white},
  showspaces=false,
  showstringspaces=false,
  showtabs=false,
  frame=single,
  captionpos=b,
  breaklines=true,
  breakatwhitespace=false,
  keywordstyle=\color{blue},
  commentstyle=\color{green!50!black},
  stringstyle=\color{orange},
  language=R
}

\geometry{left=3cm, right=3cm, top=3cm, bottom=3cm}

\setlength{\parskip}{1em}

\title{Das Gesetz der Großen Zahlen: Beweismethoden, Vergleiche und Anwendungsfälle}
\author{Valentino Galliano \\
Universität Wien \\
\texttt{a12149634@unet.univie.ac.at}}


\date{\today}

\begin{document}

\maketitle

\newpage

\begin{abstract}
    Diese Arbeit untersucht das Gesetz der Großen Zahlen (GGZ), ein zentrales Konzept der Wahrscheinlichkeitstheorie.
    Nach einer historischen Einordnung des GGZ in den letzten Jahrhunderten wird zwischen dem starken und dem schwachen GGZ formal unterschieden.
    Die Arbeit präsentiert die mathematischen Grundlagen beider Gesetze und beschreibt die Unterscheidung zwischen Konvergenz in Wahrscheinlichkeit (schwaches GGZ) und fast sicherer Konvergenz (starkes GGZ).
    Darüber hinaus stellt die Arbeit verschiedene Beweismethoden für das schwache GGZ dar, etwa mithilfe der Tschebyscheff- und Markow-Ungleichung, sowie den Zusammenhang zum zentralen Grenzwertsatz und zum Gesetz des iterierten Logarithmus.
    Um die praktische Anwendbarkeit des GGZ zu untersuchen, geht diese Arbeit auf verschiedene Anwendungsbeispiele an und diskutiert darauffolgend die Grenzen und Gegenbeispiele des GGZ.
    Alles in allem ist es das Ziel der Arbeit, die mathematischen Grundlagen, unterschiedliche Beweismethoden, praktische Anwendungsfälle und Limitationen des GGZ darzustellen.
\end{abstract}

\section{Einleitung}
\label{sec:einleitung}
Das Gesetz der Großen Zahlen (GGZ) ist ein grundlegendes Konzept in der Statistik und Wahrscheinlichkeitstheorie.
Das GGZ beschreibt die Stabilisierung von Mittelwerten bei einer zunehmenden Anzahl von Zufallsexperimenten oder Stichproben \citep{degroot2021}.
Das GGZ bildet die Grundlage für viele statistische und stochastische Methoden in der Mathematik und wird nicht nur in der Theorie, sondern auch in sämtlichen praktischen Bereichen angewendet, wie z.B. in Simulationen und in der Analyse großer Datenmengen.


An dieser Stelle ist es von Relevanz, das starke und das schwache GGZ voneinander zu unterscheiden.
Das schwache GGZ besagt, dass der arithmetische Mittelwert einer Folge unabhängiger, identisch verteilter Zufallsvariablen mit wachsendem Stichprobenumfang in der Wahrscheinlichkeit gegen den Erwartungswert konvergiert.
Das starke GGZ hingegen trifft eine strengere Aussage und es stellt die fast sichere Konvergenz sicher.
Dies bedeutet, dass der arithmetische Mittelwert mit einer Wahrscheinlichkeit von 1 gegen den Erwartungswert konvergiert.
Diese Unterscheidung ist essentiell für meine Arbeit, da sie sich vor allem auf die verschiedenen Beweise des schwachen GGZ konzentriert.
Diese Arbeit untersucht das schwache GGZ umfassend und grenzt es vom starken GGZ ab.
Darüber hinaus werden Beweise vertieft untersucht und die Beziehung zum zentralen Grenzwertsatz dargestellt.
Für diesen Zweck stützt sich die Arbeit auf eine Auswahl anerkannter Fachliteratur, insbesondere \citet{degroot2021, blitzstein2019, stoyanov2013}.

\newpage


\textbf{Beispiel: Münzwurf}

Ein klassisches Beispiel für das GGZ ist ein Münzwurf. Sei \( X_i \in \{0,1\} \) die Zufallsvariable für Wurf \( i \). Der Wert 1 steht dabei dafür, dass \enquote{Kopf} erscheint. Dann ist \( \mu = \mathbb{E}[X_i] = 0{,}5 \) bei einer fairen Münze, und das GGZ garantiert:
\[
\frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{\mathbb{P}} 0{,}5.
\]
Dies bedeutet, dass die beobachtete Wahrscheinlichkeit von \enquote{Kopf} bei wachsender Anzahl von Würfen gegen die wahre Wahrscheinlichkeit geht.
Selbstverständlich trifft diese Regel auch auf die Wahrscheinlichkeit von \enquote{Zahl} bei einer fairen Münze zu. 

Zur Veranschaulichung dieses Beispiels kann man auch eine einfache Computersimulation durchführen.
Das Ergebnis dieser Simulation in der Programmiersprache R sieht man in Abbildung \ref{fig:muenzwurf}.
Anhand dieser Simulation sieht man auch visuell, dass der empirische Mittelwert bei einer niedrigen Anzahl von Würfen noch sehr stark von dem Erwartungwert 0.5 abweicht.
Wenn man jedoch die Anzahl der Würfe erhöht (Y-Achse), sinkt diese Abweichung und der empirische Mittelwert konvergiert zum Erwartungswert.


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{Muenzwurf.png}
  \caption{Simulation eines Münzwurfs zur Veranschaulichung des Gesetzes der großen Zahlen}
  \label{fig:muenzwurf}
\end{figure}

\newpage

Die Struktur der Arbeit orientiert sich an dem folgenden Aufbau.
In Kapitel \ref{sec:hist} werden die historischen Entwicklungen des GGZ vorgestellt, sowie relevante Begriffe eingeführt.
In Kapitel \ref{sec:definitionen} erfolgt die Definition des GGZ und seiner Voraussetzungen, gefolgt von praktischen Anwendungen, sowie dem Vergleich zwischen dem starken und schwachen GGZ.
In Kapitel \ref{sec:beweismethoden} werden verschiedene Beweismethoden des schwachen GGZ vorgestellt und detailliert analysiert. Insbesondere wird auch der Bezug zum zentralen Grenzwertsatz und dem Gesetz des iterierten Logarithmus untersucht.
In Kapitel \ref{sec:anwendung} werden sämtliche Anwendungsfälle des GGZ vorgestellt und die praktische Relevanz näher beschrieben.
In Kapitel \ref{sec:grenzen} werden einige Gegenbeispiele und bekannte Grenzen des GGZ dargestellt. 
Abschließend erfolgt eine Zusammenfassung dieser Arbeit in Kapitel \ref{sec:zusammenfassung}.
Die Onlineversion der Seminararbeit findet man auf GitHub. \footnote{\url{https://github.com/ValentinoGalliano/code-seminarbeit}}



\section{Historischer Überblick und Einordnung}
\label{sec:hist}
Die Geschichte des GGZ reicht bis ins 18. Jahrhundert zurück.
Daniel Bernoulli, Schweizer Mathematiker und Physiker, formulierte im Jahr 1713 ein Ergebnis \citep{bernoulli1713}, das heute als Vorläufer des GGZ gesehen wird.
Er zeigte, dass bei wiederholter Durchführung eines Zufallsexperiments sich die relative Häufigkeit eines Ereignisses seiner wahren Wahrscheinlichkeit nähert, wenn man die Anzahl der Versuche erhöht.
Bernoulli zeigte analytisch auch, dass für unabhängige Bernoulli-Experimente die relative Häufigkeit des Erfolgs mit großer Wahrscheinlichkeit nahe bei der Erfolgswahrscheinlichkeit liegt.
Dieses Ergebnis wurde später von mehreren Autoren bestätigt und verallgemeinert \citet{poisson1837theorie, chebyshev1867}.


Erst Anfang des 20. Jahrhunderts etablierte sich in \citep{borel1909probabilites} die mathematische Fassung von \enquote{fast sicher}.
In der Wahrscheinlichkeitstheorie bedeutet \enquote{fast sicher}, dass ein Ereignis mit Wahrscheinlichkeit 1 eintritt.
Formal ausgedrückt ist also
\[\mathbb{P}(A) = 1,\]
wobei \( A \) das betrachtete Ereignis ist. Wichtig ist dabei anzumerken, dass diese Aussage nicht ausschließt, dass \( A \) trotzdem in Ausnahmefällen nicht eintritt. Der Grund dafür ist, dass auch Ereignisse mit Wahrscheinlichkeit 0 nicht unmöglich sind, sondern nur \enquote{fast nie} beobachtbar sind.
Dies zeigt auch die Wichtigkeit der Unterscheidung zwischen \enquote{sicher} und \enquote{fast sicher} in mathematischen Anwendungen.


Im 20. Jahrhundert wurde das GGZ durch Arbeiten von Mathematikern wie  Andrei Nikolajewitsch Kolmogorow und Émile Borel weiter formalisiert und erweitert.
Sie bewiesen das starke Gesetz der großen Zahlen unter allgemeinen Bedingungen und betonten somit die Bedeutung der \enquote{fast sicheren} Konvergenz.
Gleichzeitig sind mit der Zeit auch schwächere Formen des Gesetzes entstanden, wie das schwache GGZ.


Der historische Hintergrund des GGZ zeigt die zunehmende Forschung und Literatur im Bereich der Konvergenz und die erhöhte Bedeutung der mathematischen Präzision. Darüber hinaus sieht man auch, dass die Relevanz von unterschiedlichen Grenzwertsätzen in der mathematischen Theorie sowie Praxis immer mehr an Bedeutung gewonnen hat.

\section{Formale Definitionen}
\label{sec:definitionen}


In diesem Kapitel werden die notwendigen formalen Definitionen zum GGZ vorgestellt.


\subsection{Schwaches Gesetz der großen Zahlen}
\textbf{Definition:}  
Eine Folge i.i.d. Zufallsvariablen \( X_1, X_2, \dots \) mit Erwartungswert \( \mu \) und Varianz \( \sigma^2 < \infty \) genügt dem schwachen Gesetz der großen Zahlen, wenn der Stichprobenmittelwert
\[
\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i
\]
in Wahrscheinlichkeit gegen \( \mu \) konvergiert, also:
\[
\bar{X}_n \xrightarrow{\mathbb{P}} \mu.
\]

\subsection{Starkes Gesetz der großen Zahlen}

\textbf{Definition:}  
Die gleiche Folge von Zufallsvariablen \( X_1, X_2, \dots \) erfüllt das starke Gesetz der großen Zahlen, wenn der Stichprobenmittelwert fast sicher gegen \( \mu \) konvergiert, also:
\[
\mathbb{P} \left( \lim_{n \to \infty} \bar{X}_n = \mu \right) = 1.
\]
Dies ist eine stärkere Aussage, da sie Konvergenz mit Wahrscheinlichkeit 1 beschreibt \citep{degroot2021}.


\section{Beweismethoden für das schwache GGZ}
\label{sec:beweismethoden}


Es existieren verschiedene Beweismethoden für das schwache GGZ in der Literatur. Die klassische Methode verwendet die \textit{Tschebyscheff-Ungleichung} \citep{chebyshev1867}. Diese wird folgenderweise definiert.
\[
\mathbb{P} \left( \left| \bar{X}_n - \mu \right| \geq k \right) \leq \frac{\sigma^2}{k^2}
\], wobei die Variablen wie folgt beschrieben werden.
\begin{itemize}
  \item \( \bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i \): Stichprobenmittelwert einer Folge von \( n \) i.i.d. Zufallsvariablen \( X_1, X_2, \dots, X_n \).
  \item \( \mu = \mathbb{E}[X_i] \): identischer Erwartungswert der Zufallsvariablen.
  \item \( \sigma^2 = \mathbb{V}[X_i] \): identische Varianz der Zufallsvariablen.
    \item \(k > 0 \): eine beliebige reelle Zahl, die die maximal erlaubte Abweichung vom Erwartungswert als obere Schranke beschreibt.
\end{itemize}

Die Tschebyscheff-Ungleichung liefert somit eine obere Schranke für die Wahrscheinlichkeit, dass der Stichprobenmittelwert um mindestens \(k\) vom Erwartungswert abweicht.


Die Varianz des Stichprobenmittelwerts \( \bar{X}_n \) ist durch
\[
\mathbb{V}[\bar{X}_n] = \frac{\sigma^2}{n},
\]
definiert. Dies kann man in die Tschebyscheff-Ungleichung wie folgt einsetzen:
\[
\mathbb{P} \left( \left| \bar{X}_n - \mu \right| \geq k \right) \leq \frac{\sigma^2}{n k^2}.
\]
Dabei sind \(\sigma^2\) und \(k\) konstant und daraus folgt, dass der Ausdruck auf der rechten Seite gegen 0 konvergiert, wenn \(n \to \infty\). 

Daraus ergibt sich die Herleitung, dass die Wahrscheinlichkeit für eine signifikante Abweichung des Mittelwerts vom Erwartungswert mit wachsendem Stichprobenumfang verschwindet (gleich 0 ist). \(\bar{X}_n\) konvergiert also in Wahrscheinlichkeit gegen \(\mu\), was genau dem schwachen GGZ entspricht \citep{degroot2021}, also:
\[
\bar{X}_n \xrightarrow{\mathbb{P}} \mu \quad \text{für } n \to \infty.
\]


Ein alternativer Zugang, um das schwache GGZ zu beweisen, nutzt die \textit{Markow-Ungleichung} \citep{georgii2009} in Verbindung mit der Varianz von \( \bar{X}_n \). Sei \( h \colon D \to [0,\infty) \) eine monoton wachsende Funktion und \( Y \) eine Zufallsvariable mit \( Y \in D \). Dann gilt:
\[
\mathbb{P}(Y \geq a) \leq \frac{\mathbb{E}[h(Y)]}{h(a)}, \quad \text{für } a \in D.
\]
Für den Beweis des schwachen GGZ wenden wir diese Ungleichung mit der Funktion \( h(x) = x^2 \) auf die Zufallsvariable \( Y = |\bar{X}_n - \mu| \) an, wobei \( \mu = \mathbb{E}[X_i] \) und \( \bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i \). Dann ergibt sich:
\[
\mathbb{P}\left( |\bar{X}_n - \mu| \geq a \right)
= \mathbb{P}\left( (\bar{X}_n - \mu)^2 \geq a^2 \right)
\leq \frac{\mathbb{E}[(\bar{X}_n - \mu)^2]}{a^2}
= \frac{\text{Var}(\bar{X}_n)}{a^2}.
\]
Da \( X_i \) i.i.d. Zufallsvariablen sind mit endlicher Varianz \( \sigma^2 = \text{Var}(X_i) \) sind, gilt
\[
\text{Var}(\bar{X}_n) = \frac{\sigma^2}{n}.
\]
Somit ergibt sich:
\[
\mathbb{P}\left( |\bar{X}_n - \mu| \geq a \right) \leq \frac{\sigma^2}{n a^2}.
\]
Dabei sind \(\sigma^2\) und \(a\) konstant und daraus folgt, dass der Ausdruck auf der rechten Seite gegen 0 konvergiert für \( n \to \infty \), also
\[
\bar{X}_n \xrightarrow{\mathbb{P}} \mu,
\]
was widerum dem schwachen GGZ entspricht \citep{degroot2021}.



Eine dritte Methode zur Herleitung des schwachen GGZ basiert auf dem \textit{zentralen Grenzwertsatz} \citep{walz2001}. Der zentrale Grenzwertsatz beschreibt das asymptotische Verhalten der Summe bzw. des Mittelwerts einer Folge von i.i.d. verteilten Zufallsvariablen mit endlichem Erwartungswert \( \mu \) und mit endlicher Varianz \( \sigma^2 \). Er besagt, dass
\[
\sqrt{n} \left( \bar{X}_n - \mu \right) \xrightarrow{d} \mathcal{N}(0, \sigma^2),
\]
also dass die zentrierte und skalierte Stichprobenmittelwertfolge in Verteilung gegen eine Normalverteilung mit Erwartungswert 0 und Varianz \( \sigma^2 \) konvergiert. Konvergenz in Verteilung gegen eine Konstante impliziert auch Konvergenz in Wahrscheinlichkeit. Daraus folgt als Beweis für das schwache GGZ, dass \( \bar{X}_n \xrightarrow{\mathbb{P}} \mu \) \citep{degroot2021}.


Darüber hinaus findet man auch einen Bezug zwischen dem schwachen GGZ und dem \textit{Gesetz des iterierten Logarithmus} (LIL). Das LIL beschreibt die asymptotische Fluktuation des Stichprobenmittelwerts um den Erwartungswert und gilt für eine Folge i.i.d. Zufallsvariablen \( X_1, X_2, \dots \) mit \( \mathbb{E}[X_i] = 0 \) und \( \text{Var}(X_i) = \sigma^2 < \infty \). Es besagt, dass
\[
\limsup_{n \to \infty} \frac{S_n}{\sqrt{2n \log \log n}} = \sigma \quad \text{fast sicher und }
\]
\[
\liminf_{n \to \infty} \frac{S_n}{\sqrt{2n \log \log n}} = -\sigma \quad \text{fast sicher ist},
\]
wobei \( S_n = \sum_{i=1}^n X_i \) die partielle Summe ist. Daraus folgt insbesondere, dass
\[
\frac{S_n}{n} = \bar{X}_n \xrightarrow{a.s.} 0,
\]
denn durch Division der oberen Schranke \( \sqrt{2n \log \log n} \) durch \( n \) ergibt sich:
\[
\left| \bar{X}_n \right| \leq \frac{\sigma \sqrt{2 \log \log n}}{\sqrt{n}} \to 0 \quad \text{fast sicher}.
\]
Dies impliziert nicht nur Konvergenz in Wahrscheinlichkeit, sondern sogar fast sichere Konvergenz, sodass aus dem LIL unmittelbar das \textit{starke} und damit auch das \textit{schwache Gesetz der großen Zahlen} folgt.
Dadurch verbindet LIL das GGZ und den zentralen Grenzwertsatz.


\section{Anwendungen des GGZ}
\label{sec:anwendung}


Das schwache GGZ ist ein zentrales Ergebnis der Wahrscheinlichkeitstheorie und findet zahlreiche Anwendung in der Statistik, Wirtschaft, Naturwissenschaften und Technik.
Es beschreibt das Konvergenzverhalten des arithmetischen Mittels unabhängiger und identisch verteilter (i.i.d.) Zufallsvariablen gegen den Erwartungswert. Die besagte Konvergenz in Wahrscheinlichkeit erlaubt es, mit wachsendem Stichprobenumfang verlässliche Schätzungen für den Erwartungswert zu erhalten. In diesem Kapitel werden wesentliche Anwendungsbereiche des GGZ dargestellt.


\subsection{Stichprobentheorie}


In der Statistik bildet das GGZ die theoretische Grundlage für die Konsistenz von Schätzern. Der Schätzer \( \hat{\theta}_n \) eines Parameters \( \theta \) heißt in der Statistik konsistent, wenn er in Wahrscheinlichkeit gegen den wahren Parameterwert konvergiert:
\[
\hat{\theta}_n \xrightarrow{\mathbb{P}} \theta.
\]
Für den Stichprobenmittelwert \( \bar{X}_n \) bedeutet dies, dass er ein konsistenter Schätzer für den Erwartungswert \( \mu \) ist. Diese Eigenschaft erlaubt zuverlässige Aussagen über die untersuchten Gesamtdaten anhand von Stichproben.


\subsection{Finanzmathematik}


Das GGZ spielt in der Finanzmathematik auch eine wichtige Rolle, beispielsweise bei der Risikoaggregation in Banken und Versicherungsunternehmen. Sei \( X_i \) der Schaden eines Kunden im Jahr \( i \), dann beschreibt \( \bar{X}_n \) den durchschnittlichen Schaden pro Jahr über \( n \) Jahre. Das GGZ garantiert, dass sich dieser Durchschnitt langfristig dem Erwartungswert annähert. Anhand dessen können z.B. Versicherungsprämien stabil und planbar berechnet werden. Die Planbarkeit ist vor allem bei großen internationalen Firmen von großer Bedeutung, besonders wenn das Unternehmen börsennotiert ist und Aktionäre sowie Analysten bestimmte Erwartungen gegenüber dem Unternehmenserfolg haben.


\subsection{Monte-Carlo-Simulationen}

Das GGZ stellt die grundlegende theoretische Basis für das Monte-Carlo-Verfahren dar.
Bei diesem Verfahren wird der Erwartungswert von Zufallsvariablen durch Mittelung über Simulationen angenähert.
Wenn \( X_1, X_2, \dots, X_n \sim \text{Verteilung} \) unabhängige Realisierungen einer Zufallsgröße mit Erwartungswert \( \mu \) sind, dann gilt
\[
\frac{1}{n} \sum_{i=1}^n f(X_i) \xrightarrow{\mathbb{P}} \mathbb{E}[f(X)].
\]
Somit ermöglichen Monte-Carlo-Simulationen stochastische Optimierungen  \citep{degroot2021}.


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{Monte_carlo.png}
  \caption{Monte-Carlo-Simulation zur Schätzung des wahren Wertes von \texorpdfstring{$\pi$}{π}}
  \label{fig:monte_carlo}
\end{figure}


Beispielsweise kann man eine Monte-Carlo-Simulation durchführen, um den wahren Wert von \texorpdfstring{$\pi$}{π} analytisch zu schätzen.
Dabei werden zufällige Punkte in einem Einheitsquadrat generiert und geprüft, ob sie im Viertelkreis mit Radius 4 liegen.
Je mehr Punkte man generiert, desto näher wird der Anteil der Punkte in diesem Viertelkreis an dem wahren Wert von \texorpdfstring{$\pi$}{π} liegen.
Eine Veranschaulichung dieser Simulation in der Programmiersprache R sieht man in Abbildung \ref{fig:monte_carlo}.
Wie man grafisch beobachten kann, nähert sich die Monte-Carlo-Schätzung an den wahren Wert von \texorpdfstring{$\pi$}{π}, wenn man die Anzahl der Zufallspunkte erhöht.
Anhand dieses Programmierbeispiels sieht man gut, wie das GGZ praktisch angewendet werden kann, um bestimmte mathematische Problemstellungen zu lösen.


\subsection{Wirtschaft}


In der Volkswirtschaftslehre und Finanzwissenschaft beschreibt das GGZ die Verlässlichkeit von Aggregatgrößen.
Zum Beispiel kann durch die Aggregation individueller Einkommen oder Konsumentscheidungen über viele zeitliche oder örtliche Einheiten hinweg das durchschnittliche Verhalten der Bevölkerung mit hoher Genauigkeit approximiert werden.
Diese Annäherung ist von großer Bedeutung in der Volkswirtschaftslehre und Makroökonomie, weil es oft praktisch unmöglich ist, die gesamte Bevölkerung zu bestimmten Themen zu befragen.


\section{Gegenbeispiele und Grenzen des Gesetz der Großen Zahlen}
\label{sec:grenzen}


\subsection{Das schwache Gesetz der großen Zahlen}


Das schwache und das starke GGZ sind fundamentale Sätze in der Mathematik, die eine Art Stabilisierung des Mittelwertes bei einer steigenden Anzahl von Zufallsexperimenten beschreiben.
Trotz ihrer grundlegenden Bedeutung und ihrer breiten Anwendung in der Praxis sind beide Gesetze in manchen Fällen nur mit bestimmten Einschränkungen oder überhaupt nicht anwendbar.
In diesem Kapitel werden Gegenbeispiele und Grenzen beider Gesetze präsentiert, um ihre Gültigkeit und die Bedingungen, unter denen sie gelten, näher zu untersuchen.


Ein klassischer Fall, in dem das schwache GGZ nicht gilt, betrifft Zufallsvariablen, die nicht identisch verteilt sind.
Wenn die Variablen nicht identisch verteilt sind, kann der Mittelwert nicht mit Wahrscheinlichkeit 1 gegen den Erwartungswert konvergieren, selbst wenn der Erwartungswert existiert.
Ein solches Beispiel wird in der Verallgemeinerung der \textit{Bernstein'schen Ungleichung} dargestellt.
Angenommen, es gibt eine Folge von Zufallsvariablen \(X_1, X_2, \dots, X_n\), die nicht identisch verteilt sind, aber jeweils einen endlichen Erwartungswert \(\mu_i = \mathbb{E}[X_i]\) und eine endliche Varianz \(\sigma_i^2 = \text{Var}(X_i)\) haben. Die Bernstein'sche Ungleichung für die Verallgemeinerung dieser Zufallsvariablen lautet:
\[
\mathbb{P}\left( \left|\frac{1}{n} \sum_{i=1}^n X_i - \mu \right| \geq \epsilon \right) \leq 2 \exp \left( -\frac{n \epsilon^2}{2 \sum_{i=1}^n \sigma_i^2 + \frac{3}{2} \epsilon \sum_{i=1}^n |X_i - \mu_i|} \right)
\]

Diese Ungleichung zeigt also, dass für nicht identisch verteilte Zufallsvariablen die Wahrscheinlichkeit, dass der Mittelwert von den erwarteten Werten abweicht, exponentiell mit einer Kombination von Varianzen und Abweichungen der Zufallsvariablen selbst sinkt.
Trotzdem kann vorkommen, dass die Konvergenz sehr langsam oder überhaupt nicht passiert, wenn die Varianzen \(\sigma_i^2\) oder die Abweichungen \(|X_i - \mu_i|\) zu groß sind \citep{stoyanov2013}.


Ein weiteres wichtiges Gegenbeispiel für das schwache GGZ ist der Fall abhängiger Zufallsvariablen.
Gegeben eine abhängige Struktur von Zufallsvariablen \(X_1, X_2, \dots\), wie z.B. eine autoregressive Struktur:

\[
X_n = \alpha X_{n-1} + \epsilon_n \quad \text{mit} \quad \epsilon_n \sim \mathcal{N}(0, \sigma^2)
\]

In diesem Fall, selbst wenn die \(X_n\) Zufallsvariablen identisch verteilt sind und einen Erwartungswert von \(\mu = 0\) haben, kann der Mittelwert nicht gegen \(\mu\) konvergieren.
Grund dafür ist die Abhängigkeit zwischen den Zufallsvariablen, wodurch die Konvergenz nicht mehr zustande kommen kann.
Man sieht also, dass sowohl die \textbf{identische} als auch die \textbf{unabhängige} (i.i.d.) Verteilung der Zufallsvariablen wichtig ist, damit das schwache (und somit auch das starke) GGZ gilt.
Jedoch muss man bei praktischen Anwendungen oft berücksichtigen, dass diese Annahmen nicht alle erfüllt werden können.
Beispielsweise bei Finanzdaten, wie Aktienkursen oder Wechselkursen sind die Datenpunkte zeitlich voneinander abhängig (Autokorrelation), wodurch das GGZ nicht korrekt angewendet werden kann.
Ähnlich ist es auch z.B. bei Umweltdaten, wie Temperatur oder Niederschlag.
Hier sind Messpunkte oft nicht (nur) zeitlich, sondern auch räumlich voneinander abhängig.
Daher gelten meistens Konvergenzgesetze wie das GGZ standardmäßig nicht.

\subsection{Das starke Gesetz der großen Zahlen}


Ein berühmtes Gegenbeispiel für das starke GGZ ist die \textit{Cauchy-Verteilung}, die in der Mathematik oft als Beispiel für unendliche Varianz verwendet wird. Die Dichtefunktion der Cauchy-Verteilung wird folgenderweise definiert.

\[
f(x) = \frac{1}{\pi (1 + x^2)}
\]

Variablen mit einer Cauchy-Verteilung haben keinen endlichen Erwartungswert und keine endliche Varianz.
Das starke GGZ besagt jedoch, dass für eine Folge von i.i.d. Zufallsvariablen \( X_1, X_2, \dots \) mit \textit{endlichem} Erwartungswert und \textit{endlicher} Varianz folgender Zusammenhang gilt.

\[
\frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{a.s.} \mu \quad \text{für} \quad \mu = \mathbb{E}[X_i]
\]

Für die Cauchy-Verteilung existiert aber \(\mathbb{E}[X_i]\) nicht, und somit kann das starke GGZ keine fast sichere Konvergenz garantieren.
Ähnlicherweise, wenn die Zufallsvariablen eine unendliche Varianz besitzen, können ihre Mittelwerte nicht mit Wahrscheinlichkeit 1 gegen einen festen Wert konvergieren.
Somit ist die Cauchy-Verteilung der Zufallsvariablen ein Gegenbeispiel für sowohl das starke als auch das schwache GGZ.


Ein weiteres Gegenbeispiel für das starke GGZ ist die Normalverteilung der Zufallsvariablen. Gegeben sei eine Folge von i.i.d. normalverteilten Zufallsvariablen \( X_1, X_2, \dots \) mit Erwartungswert \(\mu\) und Varianz \(\sigma^2\). Dann gilt für diese Zufallsvariablen

\[
\frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{a.s.} \mu
\]

Dadurch sieht man, dass die Konvergenz für Zufallsvariablen mit solcher Verteilung zwar existiert, aber sehr langsam sein kann.
Anhand des zentralen Grenzwertsatzes wissen wir, dass die Geschwindigkeit der Konvergenz so niedrig sein kann, dass der Mittelwert eventuell über kleine Stichprobengrößen noch immer signifikante Abweichungen von \(\mu\) aufweist.
Dieses Verhalten des Mittelwerts kann man mit folgender Varianzformel für den Mittelwert der \(n\) Zufallsvariablen näher betrachten.

\[
\text{Var}\left( \frac{1}{n} \sum_{i=1}^n X_i \right) = \frac{\sigma^2}{n}
\]

Mithilfe der Formel sieht man, dass die Varianz zwar mit wachsendem \(n\) sinkt.
Jedoch erfolgt die Konvergenz in der Praxis sehr langsam, wodurch das starke GGZ in vielen Anwendungsfällen nicht zielführend verwendet werden kann, weil sich der Mittelwert nicht innerhalb einer realistischen Stichprobengröße stabilisiert.


Wie bereits beschrieben, ist das starke GGZ strenger als das schwache Gesetz.
Anders gesagt, garantiert das starke Gesetz eine fast sichere Konvergenz, während das schwache Gesetz lediglich eine Konvergenz in Wahrscheinlichkeit garantiert.
Die unterschiedlichen Konvergenzen und Voraussetzungen führen dazu, dass beide Gesetze in der Praxis anders verwendet werden.


\section{Zusammenfassung}
\label{sec:zusammenfassung}


Das Gesetz der großen Zahlen ist eine fundamentale Aussage in der Mathematik, die vor mehreren Jahrhunderten etabliert wurde und mittlerweile in diversen Anwendungsfällen verwendet wird.
Das GGZ besagt die Stabilität in stochastischen Systemen und Prozessen und liefert die theoretische Grundlage für viele weitere Methoden in verschiedenen Bereichen.
Es erklärt, warum durchschnittliches Verhalten verlässlich ist, obwohl einzelne Beobachtungen zufällig sind.
Diese Aussage ist äußerst relevant, wenn man mit großen Datenmengen arbeitet, wobei die Analyse jeder einzelnen Beobachtung praktisch unmöglich ist.
Für die Zwecke dieser Arbeit wurde auch der Unterschied zwischen dem starken und schwachen GGZ veranschaulicht.
Dieser liegt hauptsächlich in der Art der Konvergenz.
Das schwache GGZ besagt eine Konvergenz in Wahrscheinlichkeit, während das starke GGZ eine fast sichere Konvergenz garantiert.
Dadurch trifft das starke GGZ eine stärkere Aussage, und dementsprechend gilt das schwache GGZ immer, wenn das starke GGZ gilt, aber nicht umgekehrt.
Einige Beispiele für diesen Zusammenhang werden in \citet{stoyanov2013} diskutiert.


Diese Arbeit beschränkt sich auf die theoretische Darstellung und den historischen Kontext des GGZ.
Insbesondere wird die Unterscheidung zwischen starkem und schwachem GGZ dargestellt.
In dieser Arbeit wurde jedoch keine empirische Untersuchung zur Veranschaulichung der Konvergenzeigenschaften durchgeführt und somit keine eigenen Daten gesammelt.
Darüber hinaus wurde hier nicht auf einzelne Verallgemeinerungen und Ausnahmen eingegangen.
Aus diesen Einschränkungen ergeben sich aber zahlreiche Möglichkeiten für weitere Forschung.
Beispielsweise könnte sich zukünftige Forschung näher mit der Anwendung des GGZ unter realitätsnäheren Bedingungen beschäftigen.
Beispielsweise sind Zeitreihenanalysen in Bezug auf das GGZ in den Finanzwissenschaften von großer Bedeutung.
Weiters könnten auch quantitative Merkmale des GGZ, wie z.B. die Geschwindigkeit der Konvergenz, näher analysiert werden, um die praktische Anwendbarkeit des GGZ detailliert zu untersuchen.


\newpage

\bibliographystyle{apalike}
\bibliography{literatur}

\newpage

\appendix
\section{Appendix}

\section*{R-Code zur Simulation von Münzwürfen}

\begin{lstlisting}[language=R, caption={Simulation von Münzwürfen mit R}, label={lst:muenzenwurf}]
n <- 10000
set.seed(123)
w <- rbinom(n, size = 1, prob = 0.5)
m <- cumsum(w) / 1:n
e <- 0.5
plot(1:n, m, type = "l", col = "blue",
     xlab = "Anzahl der Würfe",
     ylab = "Empirischer Mittelwert",
     main = "Beispiel: Münzwurf")
abline(h = e, col = "red", lty = 2)
legend("topright", legend = c("Empirischer Mittelwert", "Erwartungswert (0.5)"),
       col = c("blue", "red"), lty = c(1,2), bty = "n")
\end{lstlisting}

\section*{R-Code zur Schätzung von \texorpdfstring{$\pi$}{π}}

\begin{lstlisting}[language=R, caption={Monte-Carlo-Schätzung von $\pi$ mit R}, label={lst:pi_montecarlo}]
n <- 10000
schritt <- 100
x <- runif(n)
y <- runif(n)
ist_drinnen <- x^2 + y^2 <= 1
pi <- numeric(n / schritt)
for (i in seq(schritt, n, by = schritt)) {
  pi[i / schritt] <- 4 * mean(ist_drinnen[1:i])
}
x_werte <- seq(schritt, n, by = schritt)
plot(x_werte, pi, type = "l", col = "blue", lwd = 2,
     main = expression("Monte Carlo-Schätzung von Pi"),
     xlab = "Anzahl zufälliger Punkte",
     ylim = c(2.5, 3.7))
abline(h = pi, col = "red", lty = 2, lwd = 2)
legend("topright", legend = c("Schätzung", "wahrer Wert von Pi"),
       col = c("blue", "red"), lty = c(1, 2), lwd = 2)
\end{lstlisting}

\end{document}
